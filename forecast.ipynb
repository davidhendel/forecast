{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting stream gap analysis for future surveys\n",
    "\n",
    "Codebase & instructions for the model of Hendel & Bovy 2020, based primarily on the **streampepper** formalism of Bovy, Erkal & Sanders 2017\n",
    "\n",
    "The method is designed to be extensible to new streams and/or survey parameters.\n",
    "\n",
    "To add new streams, one needs\n",
    "1. The stream's orbit, age, & velocity dispersion\n",
    "2. Star counts in an existing survey\n",
    "3. An assumed stellar population (age, metallicity, and stellar mass function slope)\n",
    "4. A choice of coordinate system & mock survey area\n",
    "5. (optional) To include background stars, a Galaxia (Sharma et al. 2011) mock halo survey at the stream position\n",
    "\n",
    "To add a new survey, one needs\n",
    "1. Isochrone tables (preferably matched to the Galaxia grid, see isochrone_handling.py)\n",
    "2. An error model, e.g. $\\Delta_{r}(r)$, in at least two photometric bands."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<img src=\".png\" ALIGN=left style=\"margin: 0px 30px 30px 0px;\" width=\"120\"/> <font size=\"6\"> text </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#set environment variables for your directory structure in .bash_profile, e.g.\n",
    "#    export _FORECAST_DATA_DIR=/path/to/forecast/\n",
    "_DATADIR  =  os.environ['_FORECAST_DATA_DIR']\n",
    "_LOCALDIR =  os.environ['_FORECAST_LOCAL_DIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up stream models\n",
    "\n",
    "First we create the streampepper dynamical models for each stream. This is done by make_streampepper_models file which has the necessary parameters and uses them to call the streammodel_util.py file. The latter generalizes the old pal5_util and gd1_util files. There will be a separate leading-tail and trailing-tail model for each. \n",
    "\n",
    "Depending on the potential, orbit, and desired number of times that impacts can happen these models can take quite some time to generate so the script can be run with multiprocessing enabled, if desired. It returns pickles of the models for quick restarts after the inital calculation.\n",
    "\n",
    "New streams can be easily added by reproducing the config format seen for Pal5, Phoenix and GD-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create models:\n",
    "#python3 make_streampepper_models.py pal5 gd1 phx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_streampepper_models import pal5_config, gd1_config, phx_config\n",
    "\n",
    "for config in [pal5_config, gd1_config, phx_config]:\n",
    "    for i, tail in enumerate['leading, trailing']:\n",
    "        config.sdf = {tail:}\n",
    "\n",
    "pal5_l = pickle.load(_DATADIR+'pal5_64sampling_leading.pkl', encoding='latin1')\n",
    "pal5_t = pickle.load(_DATADIR+'pal5_64sampling_trailing.pkl', encoding='latin1')\n",
    "gd1_l  = pickle.load(_DATADIR+'gd1_64sampling_leading.pkl', encoding='latin1')\n",
    "gd1_t  = pickle.load(_DATADIR+'gd1_64sampling_trailing.pkl', encoding='latin1')\n",
    "phx_l  = pickle.load(_DATADIR+'phx_64sampling_leading.pkl', encoding='latin1')\n",
    "phx_t  = pickle.load(_DATADIR+'phx_64sampling_trailing.pkl', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galaxia background model\n",
    "\n",
    "Galaxia needs to be installed; to work with the resulting .ebf files one must use Python 2 for the ebfpy package. For me, pip2 install ebfpy was enough; we can call python2 with subprocess to generate a more convenient fits format (ebf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observational coordinates\n",
    "\n",
    "Streammodel_util also allows for adding custom stream-oriented coordinate systems to the models as well as calculating the star count density in a selected 'observed' region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isochrone handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Bayesian Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting stream gap analysis for future surveys\n",
    "\n",
    "Codebase & instructions for the model of Hendel & Bovy 2020, based primarily on the **streampepper** formalism of Bovy, Erkal & Sanders 2017\n",
    "\n",
    "The method is designed to be extensible to new streams and/or survey parameters.\n",
    "\n",
    "To add new streams, one needs\n",
    "1. The stream's orbit, age, & velocity dispersion\n",
    "2. Star counts in an existing survey\n",
    "3. An assumed stellar population (age, metallicity, and stellar mass function slope)\n",
    "4. A choice of coordinate system & mock survey area\n",
    "5. (optional) To include background stars, a Galaxia (Sharma et al. 2011) mock halo survey at the stream position\n",
    "\n",
    "To add a new survey, one needs\n",
    "1. Isochrone tables (preferably matched to the Galaxia grid, see isochrone_handling.py)\n",
    "2. An error model, e.g. $\\Delta_{r}(r)$, in at least two photometric bands."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<img src=\".png\" ALIGN=left style=\"margin: 0px 30px 30px 0px;\" width=\"120\"/> <font size=\"6\"> text </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import galpy\n",
    "import pickle\n",
    "from astropy.table import Table,Column,Row\n",
    "#set environment variables for your directory structure in .bash_profile, e.g.\n",
    "#    export _FORECAST_DATA_DIR=/path/to/forecast/\n",
    "_DATADIR  =  os.environ['_FORECAST_DATA_DIR']\n",
    "_LOCALDIR =  os.environ['_FORECAST_LOCAL_DIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up stream models\n",
    "\n",
    "First we create the streampepper dynamical models for each stream. This is done by make_streampepper_models file which has the necessary parameters and uses them to call the streammodel_util.py file. The latter generalizes the old pal5_util and gd1_util files. There will be a separate leading-tail and trailing-tail model for each. \n",
    "\n",
    "Depending on the potential, orbit, and desired number of times that impacts can happen these models can take quite some time to generate so the script can be run with multiprocessing enabled, if desired. It returns pickles of the models for quick restarts after the inital calculation.\n",
    "\n",
    "New streams can be easily added by reproducing the config format seen for Pal5, Phoenix and GD-1.\n",
    "\n",
    "Streammodel_util also allows for adding custom stream-oriented coordinate systems to the models as well as calculating the star count density in a selected 'observed' region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create models:\n",
    "#run this in your command line (can take hours)\n",
    "#python3 make_streampepper_models.py pal5 gd1 phx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leading DF loaded\n",
      "Trailing DF loaded\n",
      "Leading DF loaded\n",
      "Trailing DF loaded\n",
      "Leading DF loaded\n",
      "Trailing DF loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<streampepperdf.streampepperdf at 0x11615a5c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from make_streampepper_models import pal5_config, gd1_config, phx_config\n",
    "\n",
    "for config in [pal5_config, gd1_config, phx_config]:\n",
    "    #load pickled models & coordinate systems into config.sdf\n",
    "    config.load()\n",
    "    \n",
    "pal5_config.sdf['trailing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galaxia background model\n",
    "\n",
    "Naturally [Galaxia](http://galaxia.sourceforge.net/Galaxia3pub.html) (Sharma et al. 2011) needs to be installed. To work with the resulting .ebf files one must use Python 2 for the ebfpy package. For me, pip2 install ebfpy was enough; we can call python2 with subprocess to generate a more convenient .fits format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pal5_bg.ebf already exists!\n",
      "gd1_bg.ebf already exists!\n",
      "phx_bg.ebf already exists!\n"
     ]
    }
   ],
   "source": [
    "import bg\n",
    "from astropy.io import fits as pyfits\n",
    "\n",
    "for config in [pal5_config, gd1_config, phx_config]:\n",
    "    #run Galaxia to calculate all stars in a 1 deg area around the progenitor \n",
    "    #position; creates a .fits table in outputDir for use with the isochrone handling\n",
    "    config.bgfname =  _DATADIR+'galaxia_files/'+config.name+'_bg.fits'\n",
    "    bg.run_galaxia(config.name+'_bg.ebf', config.name+'.param', \n",
    "                   outputDir = _DATADIR+'galaxia_files/', \n",
    "                   lon = config.obs.SkyCoord().galactic.l.value,\n",
    "                   lat = config.obs.SkyCoord().galactic.b.value)                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load surveys and isochrones (set remake=True, save=True if you haven't created them before)\n",
    "\n",
    "Use isochrone tables & error model to calculate how many of the stars in each background field will be confused with the stream's isochrone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=6</i>\n",
       "<table id=\"table5426233240\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th></th><th>Pal 5</th><th>GD-1</th><th>Phoenix</th></tr></thead>\n",
       "<thead><tr><th>str12</th><th>int64</th><th>int64</th><th>int64</th></tr></thead>\n",
       "<tr><td>SDSS</td><td>1403</td><td>269</td><td>531</td></tr>\n",
       "<tr><td>CFHT</td><td>1472</td><td>131</td><td>407</td></tr>\n",
       "<tr><td>DES</td><td>1384</td><td>49</td><td>370</td></tr>\n",
       "<tr><td>LSST 1-year</td><td>681</td><td>76</td><td>216</td></tr>\n",
       "<tr><td>LSST 10-year</td><td>531</td><td>84</td><td>186</td></tr>\n",
       "<tr><td>WFIRST</td><td>273</td><td>25</td><td>93</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=6>\n",
       "             Pal 5  GD-1 Phoenix\n",
       "   str12     int64 int64  int64 \n",
       "------------ ----- ----- -------\n",
       "        SDSS  1403   269     531\n",
       "        CFHT  1472   131     407\n",
       "         DES  1384    49     370\n",
       " LSST 1-year   681    76     216\n",
       "LSST 10-year   531    84     186\n",
       "      WFIRST   273    25      93"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import survey_config\n",
    "from survey_config import sdss_survey, cfht_survey, des_survey, lsst_survey, lsst10_survey, wfirst_survey\n",
    "\n",
    "for config in [sdss_survey, cfht_survey, des_survey, lsst_survey, lsst10_survey, wfirst_survey]:\n",
    "    config.load_iso_interps(remake=False, save=False, maxlabel=4)\n",
    "    \n",
    "streams = [pal5_config, gd1_config, phx_config]\n",
    "surveys = [sdss_survey, cfht_survey, des_survey, lsst_survey, lsst10_survey, wfirst_survey]\n",
    "d = np.zeros((len(streams), len(surveys)))\n",
    "\n",
    "for i, stream in enumerate(streams):\n",
    "    for j, survey in enumerate(surveys):\n",
    "        d[i,j]=survey_config.calc_star_bg(stream, survey)\n",
    "        #print(stream.name, survey.name, d[i,j])\n",
    "\n",
    "t=Table()\n",
    "t[' '] = ['SDSS', 'CFHT', 'DES', 'LSST 1-year', 'LSST 10-year', 'WFIRST']\n",
    "t.add_columns(d.astype(int), names=['Pal 5', 'GD-1', 'Phoenix'])\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate number of stream stars in new surveys by finding the minimum visible stellar in the observations and integrating the mass function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfht 0.5485823537437436 sdss 0.7178876489989989 0.1265313453343085\n",
      "cfht 0.5485823537437436 cfht 0.5485823537437436 0.3397694518540607\n",
      "cfht 0.5485823537437436 des 0.6033575963263262 0.26757443262772934\n",
      "cfht 0.5485823537437436 lsst 0.49629689491491485 0.41212951376703577\n",
      "cfht 0.5485823537437436 lsst10 0.40417489602602596 0.549601342785451\n",
      "cfht 0.5485823537437436 wfirst 0.15685637648648648 1.0289944078230457\n"
     ]
    }
   ],
   "source": [
    "survey_config.calc_nstars(pal5_config, cfht_survey, new_surveys=surveys)\n",
    "survey_config.calc_nstars(phx_config, des_survey, new_surveys=surveys)\n",
    "survey_config.calc_nstars(gd1_config, 'all', new_surveys=surveys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=6</i>\n",
       "<table id=\"table4988777696\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th></th><th>Pal 5</th><th>Phoenix</th><th>GD-1</th></tr></thead>\n",
       "<thead><tr><th>str12</th><th>int64</th><th>int64</th><th>int64</th></tr></thead>\n",
       "<tr><td>SDSS</td><td>1191</td><td>576</td><td>7383</td></tr>\n",
       "<tr><td>CFHT</td><td>3200</td><td>1209</td><td>12453</td></tr>\n",
       "<tr><td>DES</td><td>2520</td><td>999</td><td>10304</td></tr>\n",
       "<tr><td>LSST 1-year</td><td>3881</td><td>1440</td><td>15657</td></tr>\n",
       "<tr><td>LSST 10-year</td><td>5176</td><td>2003</td><td>20350</td></tr>\n",
       "<tr><td>WFIRST</td><td>9691</td><td>3407</td><td>26676</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=6>\n",
       "             Pal 5 Phoenix  GD-1\n",
       "   str12     int64  int64  int64\n",
       "------------ ----- ------- -----\n",
       "        SDSS  1191     576  7383\n",
       "        CFHT  3200    1209 12453\n",
       "         DES  2520     999 10304\n",
       " LSST 1-year  3881    1440 15657\n",
       "LSST 10-year  5176    2003 20350\n",
       "      WFIRST  9691    3407 26676"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=Table()\n",
    "r[' '] = ['SDSS', 'CFHT', 'DES', 'LSST 1-year', 'LSST 10-year', 'WFIRST']\n",
    "order = ['sdss','cfht','des','lsst','lsst10','wfirst']\n",
    "r.add_column([pal5_config.nstars[key] for key in order], name = 'Pal 5')\n",
    "r.add_column([phx_config.nstars[key] for key in order], name = 'Phoenix')\n",
    "r.add_column([gd1_config.nstars[key] for key in order], name = 'GD-1')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Bayesian Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hendel/projects/streamgaps/forecast/data/model_picklespal5_64sampling_leading.pkl\n"
     ]
    }
   ],
   "source": [
    "print(_DATADIR+'model_pickles'+pal5_config.name+'_'+pal5_config.ntimes+'_leading.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<survey_config.survey at 0x1115b48d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal5_config.obs.dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
